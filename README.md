# RECONHECIMENTO DE SINAIS DINÃ‚MICOS DA LÃNGUA BRASILEIRA DE SINAIS POR MEIO DE REDES NEURAIS CONVOLUCIONAIS

---

## âœ… Requisitos

- **Python 3.10.x**
  - Esta foi a versÃ£o utilizada em todo o desenvolvimento. Recomenda-se fortemente manter essa versÃ£o para garantir compatibilidade com bibliotecas como `torch`, `tensorflow`, `opencv` e `imageio`.

- **Sistema Operacional**
  - Recomenda-se Linux (Ubuntu ou derivados.

- **Outros**
  - Git
  - pyenv para gerenciar versÃµes do Python

---

## ğŸš€ InstalaÃ§Ã£o

### 1. Configure o Python 3.10

Usando pyenv:

pyenv install 3.10.12
pyenv local 3.10.12

Verifique a versÃ£o:

python --version  # Deve retornar Python 3.10.x

### 2. Crie e ative o ambiente virtual

python -m venv venv
source venv/bin/activate

### 3. Instale as dependÃªncias

pip install --upgrade pip
pip install -e .

---

## ğŸ“ Estrutura do Projeto

- `data/raw_videos/` â†’ VÃ­deos brutos da base de dados (diretamente das fontes `vlibras` e `ines_gov`)
- `data/numpy_data/` â†’ Arquivos `.npy` com os frames tratados, redimensionados e normalizados
- `data/split/` â†’ Dados organizados em `train/`, `val/` e `test/` para os experimentos
- `notebooks/` â†’ Notebooks de treinamento das CNNs e do pipeline de prÃ©-processamento (executÃ¡veis manualmente)
- `reports/` â†’ RelatÃ³rios gerados pelas CNNs com mÃ©tricas por classe e matrizes de confusÃ£o
- `saved_models/` â†’ Arquivos `.pth` com os pesos salvos de cada arquitetura testada
- `src/models/` â†’ Arquiteturas CNNs customizadas.  
  ContÃ©m os **cÃ³digos completos das redes neurais**, com todas as **configuraÃ§Ãµes especÃ­ficas**, camadas, mÃ©todos de avaliaÃ§Ã£o e geraÃ§Ã£o de relatÃ³rios.
- `src/preprocess/` â†’ Pipeline completo de prÃ©-processamento.  
  Inclui os **mÃ³dulos responsÃ¡veis por carregar vÃ­deos, extrair e tratar frames**, aplicar normalizaÃ§Ã£o, redimensionamento e salvar os dados em formato `.npy`.  Ali tambÃ©m estÃ£o definidos todos os **parÃ¢metros utilizados**, alÃ©m de um script auxiliar para execuÃ§Ã£o rÃ¡pida (`run_preprocessing.py`).
- `src/preprocess/run_preprocessing.py` â†’ Script rÃ¡pido para execuÃ§Ã£o do prÃ©-processamento completo (versÃ£o nÃ£o visual, usada durante o desenvolvimento)
- `requirements.txt` â†’ Lista de bibliotecas necessÃ¡rias
- `setup.py` â†’ Script de instalaÃ§Ã£o e configuraÃ§Ã£o do projeto como pacote Python

---

## âš™ï¸ Como utilizar

### 1. PrÃ©-processamento

Os dados jÃ¡ estÃ£o prÃ©-processados.  
Para repetir o processo:

1. Apague o **somente o conteÃºdo, nÃ£o o direotiro** de:
   - data/numpy_data/
   - data/split/train/, val/, test/
2. Execute notebooks/preprocess.ipynb

---

### 2. Treinar os Modelos

Use os notebooks:

- alexnet_test.ipynb
- densenet_test.ipynb
- inceptionv3_test.ipynb
- resnet_test.ipynb
- vgg16net_test.ipynb

Eles geram:

- Modelos treinados e salvos em `saved_models/`
- RelatÃ³rios de desempenho e matrizes de confusÃ£o salvos em `notebooks/`  
  (podem ser movidos manualmente para `reports/` para organizaÃ§Ã£o)

> âš ï¸ Caso deseje repetir os testes ou treinar novamente os modelos, **apague apenas os arquivos `.pth` em `saved_models/** NÃ£o Ã© necessÃ¡rio apagar os diretÃ³rios.**

---

## ğŸ“Š RelatÃ³rios

Em `reports/`, estÃ£o organizados:

- RelatÃ³rios de desempenho por arquitetura (em `.txt`)
- Matrizes de confusÃ£o dos conjuntos de validaÃ§Ã£o e teste (em `.png`)
- Todos os arquivos presentes correspondem Ã  **Ãºltima rodada de testes** executada por mim

> âš ï¸ Caso execute novos testes, os relatÃ³rios e imagens serÃ£o gerados novamente nos `notebooks/`  
> VocÃª pode movÃª-los manualmente para `reports/` para manter a organizaÃ§Ã£o.

